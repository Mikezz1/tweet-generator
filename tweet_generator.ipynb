{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8Rz50hq6JxJ"
   },
   "source": [
    "# Fine-tuning gpt-2 on Trump's tweets dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EsH69w33cM5J",
    "outputId": "7b640653-2dd4-44e6-f127-a05a68a43c71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/b1/41130a228dd656a1a31ba281598a968320283f48d42782845f6ba567f00b/transformers-4.2.2-py3-none-any.whl (1.8MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8MB 16.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 54.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
      "Collecting tokenizers==0.9.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9MB 56.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=1100cc2dbf706c480942993eb53612fa703edfd8d2e4c5a4a56f98335a55784c\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sacremoses, tokenizers, transformers\n",
      "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import GPT2Tokenizer\n",
    "from transformers import GPT2LMHeadModel, GPT2Config, AdamW\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, random_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mjkFoSMjvc2X"
   },
   "outputs": [],
   "source": [
    "# seed everything\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBhPn4U6vBYI"
   },
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset is tiny, but it still "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RpXts1jAcp7v"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data.csv')['tweet']\n",
    "data = data.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H0oILJwbvF8X"
   },
   "source": [
    "## Loading pretrained gpt2 tokenizer & creating custom datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132,
     "referenced_widgets": [
      "b7158db477fe4c12878b87e95ad81a83",
      "51fde4bbe58447f7ab6ce3850f63afdb",
      "00d583051f46415eac11b393ec94e0de",
      "e1c7b76337a747ef8eca7fef1b9c56f2",
      "c724c430304d4630a0cbe5016d1bb575",
      "5f4e81498061424bb0dde83ac0acee7f",
      "885b3c8569b84bf582645a27e9a9534e",
      "c798caa720de47c496262b19035bc57e",
      "34c3ea38e6c24096984029dbf798028b",
      "a5ae5ad86ffb483b94ccdf56c801d684",
      "11ec75b0aae54976a3272c4ab16c550b",
      "380a8ea1706f4149a7835a181618b5d0",
      "985bb20dd0c644278b521d64c98171af",
      "21691e53a918498997f4cd456fa6f80f",
      "ffb6cb51d0284310ab7df18074285703",
      "c128c8e6580f4159a0d09f44ec242919"
     ]
    },
    "id": "jDPIFZlwf2Uq",
    "outputId": "961a732d-d86c-4705-f6d7-03dbed41e366"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7158db477fe4c12878b87e95ad81a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c3ea38e6c24096984029dbf798028b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# specify technical tokens\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', \n",
    "                                          bos_token='<|BOS|>', \n",
    "                                          eos_token='<|EOS|>', \n",
    "                                          pad_token='<|PAD|>')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "gNVnNQldg3Dp"
   },
   "outputs": [],
   "source": [
    "class TRUMPdataset(Dataset):\n",
    "\n",
    "    def __init__(self, corpus, tokenizer, gpt2_type=\"gpt2\", max_length=40):\n",
    "\n",
    "        self.tokenizer = tokenizer \n",
    "        self.input_ids = []\n",
    "        self.attention_masks = []\n",
    "\n",
    "        for sequence in corpus:\n",
    "        # Loop through all corpus to add eos, bos and padding + truncate\n",
    "            encodings_dict = tokenizer('<|BOS|>'+ sequence + '<|EOS|>', \n",
    "                                         truncation=True, \n",
    "                                         max_length=max_length,\n",
    "                                         padding = 'max_length')\n",
    "\n",
    "            # assign tokenizer output to id's and attention masks   \n",
    "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
    "            self.attention_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
    "    \n",
    "    # add standard datset methods\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.attention_masks[idx] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "XhcE7zndhZ8U"
   },
   "outputs": [],
   "source": [
    "alldataset = TRUMPdataset(data, tokenizer, max_length=60)\n",
    "tr = int(0.8 * len(alldataset))\n",
    "vl = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, (tr, vl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "1K5LhKbrh7DZ"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  \n",
    "            sampler = RandomSampler(train_dataset),\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, \n",
    "            sampler = SequentialSampler(val_dataset),\n",
    "            batch_size = batch_size \n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XdDSrRozvqak"
   },
   "source": [
    "## Loading pretrained model & building train/val loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115,
     "referenced_widgets": [
      "eeeff05e1f5c4dde9b0d5b01ae47001a",
      "124ce7e129144d1c98138581ee0d2b31",
      "6566f1451a144451a9bdc90ad29dd0b8",
      "4f12cad30a194f70b169f588265a6600",
      "67102cf93a364b048c88331980dbd646",
      "af12e10c7fcb4c9a9cad455b8a6e8b05",
      "0e641c1023ae4f6285237f9e1a6f5546",
      "7c6c0b2328fe4d96ac8ff4ca47163435",
      "c717761fd1d642e68008a9542ad1a38a",
      "d4ff59780f4f4a69926cc1ce122ab45a",
      "248c131b02d24c828435831677d63ac0",
      "26be1de9a7aa422c90a465cb782590a8",
      "971bacbb7eb44afc857674f725cfa283",
      "173d31bb958e4ad9980666d51defb170",
      "daa1b7b794dc4713aefa76f771029e35",
      "4c084ab5125b4283b4ef7dfe135a3f76"
     ]
    },
    "id": "tBkshAzMiP7T",
    "outputId": "32e8a08c-bb0e-452a-92fc-90d53a6d1ced"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeeff05e1f5c4dde9b0d5b01ae47001a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=665.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c717761fd1d642e68008a9542ad1a38a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=548118077.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=configuration)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model = model.to(device)\n",
    "\n",
    "# set some of the standard lr values from 5e-5 to 5e-4\n",
    "optimizer = AdamW(model.parameters(), lr = 5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1Bb-NCsxijp7"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, num_epochs =3, ):\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        print(f'Epoch: {epoch}')\n",
    "\n",
    "        total_train_loss = 0\n",
    "        model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_loader):\n",
    "\n",
    "        input_ids = batch[0].to(device)\n",
    "        labels = batch[0].to(device)\n",
    "        masks = batch[1].to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        output = model(input_ids, labels=labels, attention_mask = masks, token_type_ids=None)\n",
    "        loss = output[0]\n",
    "        batch_loss = loss.item() \n",
    "        total_train_loss += batch_loss  \n",
    "\n",
    "        if step % 50 == 0:\n",
    "            print(f'Batch {step} of {len(train_loader)}, loss = {batch_loss}')\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)  \n",
    "\n",
    "\n",
    "\n",
    "def evaluate(model, val_loader):\n",
    "    total_eval_loss=0\n",
    "    for batch in val_loader:\n",
    "\n",
    "        input_ids = batch[0].to(device)\n",
    "        labels = batch[0].to(device)\n",
    "        masks = batch[1].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "          \n",
    "          outputs  = model(input_ids,  \n",
    "                             attention_mask = masks,\n",
    "                             labels = labels)\n",
    "          \n",
    "          loss = outputs[0]  \n",
    "            \n",
    "        batch_loss = loss.item()\n",
    "        total_eval_loss += batch_loss        \n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    print(f'Validation loss is {avg_val_loss}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UuI2Z1WXwBw5"
   },
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H4dLaIQ5itbN",
    "outputId": "84f92e49-4976-46d8-d086-e2f9067ad2e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Batch 0 of 142, loss = 68.0325927734375\n",
      "Batch 50 of 142, loss = 3.5193979740142822\n",
      "Batch 100 of 142, loss = 3.412783145904541\n",
      "Epoch: 1\n",
      "Batch 0 of 142, loss = 2.7614707946777344\n",
      "Batch 50 of 142, loss = 2.785888671875\n",
      "Batch 100 of 142, loss = 2.4498608112335205\n",
      "Epoch: 2\n",
      "Batch 0 of 142, loss = 2.271756172180176\n",
      "Batch 50 of 142, loss = 2.420562267303467\n",
      "Batch 100 of 142, loss = 2.0707485675811768\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NmOZaQUri481",
    "outputId": "b15bb700-804b-4b79-a8c1-fe93b71ee512"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss is 2.6227709386083813\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, validation_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zasPlui-OnYl",
    "outputId": "7db1860f-3078-41bb-bbbe-0d914d5ca66d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/drive/TwitterGPT2/model/tokenizer_config.json',\n",
       " '/drive/TwitterGPT2/model/special_tokens_map.json',\n",
       " '/drive/TwitterGPT2/model/vocab.json',\n",
       " '/drive/TwitterGPT2/model/merges.txt',\n",
       " '/drive/TwitterGPT2/model/added_tokens.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model\n",
    "save_path = '/drive/TwitterGPT2/model'\n",
    "model_to_save = model.module if hasattr(model, 'module') else model\n",
    "model_to_save.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "sO4_LcCJwQsq"
   },
   "outputs": [],
   "source": [
    "#load model\n",
    "save_path = '/drive/TwitterGPT2/model'\n",
    "model = GPT2LMHeadModel.from_pretrained(save_path)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(save_path)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZbIgQ0ZtwHde"
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfwDnAIcZXNh"
   },
   "source": [
    "### Greedy search\n",
    "This model chooses the most probable next word. It has some problems (i.e. repeating phrases) and sounds not human-like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3UpL6RSNYUiw",
    "outputId": "5daa29c3-740b-44ae-feb3-556094a03cb5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: The Democrats are trying to make it impossible for the Republican Party to win the House. They are trying to make it impossible for the Republican Party to win the Senate. They are trying to make it impossible for the Republican Party to win the House. They are trying to make it impossible for the Republican Party to win the House. They are trying to\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds = torch.tensor(tokenizer.encode(\"<|BOS|>\")).unsqueeze(0)\n",
    "ids = ids.to(device)\n",
    "\n",
    "samples = model.generate(ids, max_length = 70)\n",
    "\n",
    "for i, sample_output in enumerate(samples):\n",
    "    print(f\"{i}: {tokenizer.decode(sample_output, skip_special_tokens=True)}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ik87lfV1cYw"
   },
   "source": [
    "### Beam  search\n",
    "The second approach to text generation is based on choosing k most probable words at each timestamp and iterate until the end of the sequence. Then, model outputs the most probable sequence out of them. Such method outperforms simple greedy search, which looks only on one next word. We also use n_gram penalty to prevent model from repeating same passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_y3fLlBx1FOb",
    "outputId": "e60b01e3-44dd-4128-f2bd-a1f117bb7743"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: The failing @nytimes is a disgrace to journalism. They should be ashamed of themselves and their dishonesty. I hope they will be forced to apologize to the people of the U.S. for what they have done, and for the terrible things that have been said about them. https://t\n",
      "\n",
      "\n",
      "1: The failing @nytimes is a disgrace to journalism. They should be ashamed of themselves and their dishonesty. I hope they will be forced to apologize to the people of the U.S. for what they have done, and for the terrible things that have been said about them. https://t\n",
      "\n",
      "\n",
      "2: The failing @nytimes is a disgrace to journalism. They should be ashamed of themselves and their dishonesty. I hope they will be forced to apologize to the people of the U.S. for what they have done, and for the terrible things that have been said about me. https://t\n",
      "\n",
      "\n",
      "3: The failing @nytimes is a disgrace to journalism. They should be ashamed of themselves and their dishonesty. I hope they will be forced to apologize to the people of the U.S. for what they have done, and for the terrible things that have been done to them. https://t\n",
      "\n",
      "\n",
      "4: The failing @nytimes is a disgrace to journalism. They should be ashamed of themselves and their dishonesty. I hope they will be forced to apologize to the people of the U.S. for what they have done, and for the terrible things that have been said about me. https://t\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ids = torch.tensor(tokenizer.encode(\"<|BOS|>\")).unsqueeze(0)\n",
    "ids = ids.to(device)\n",
    "\n",
    "samples = model.generate(       ids, \n",
    "                                num_beams=5, \n",
    "                                early_stopping=True, \n",
    "                                max_length = 70,\n",
    "                                no_repeat_ngram_size=2,\n",
    "                                num_return_sequences=5\n",
    "                                )\n",
    "\n",
    "for i, sample_output in enumerate(samples):\n",
    "    print(f\"{i}: {tokenizer.decode(sample_output, skip_special_tokens=True)}\\n\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_yEmGiwxPnB"
   },
   "source": [
    "### More complicated way to generate sequnces is the probabalistic Top-K sampling\n",
    "This method randomly samples words from a set of K most probable ones at each time stamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WXqpzvA1mOW3",
    "outputId": "bac11671-61ec-4fb7-b2a3-d80a3d256763"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: So now we have more votes in the Supreme Court than is necessary to secure the Supreme Court, a number that has never been seen before by a Supreme Court Justices. So when will somebody who has voted for the most corrupt President in our history, or should have taken the Radical Left vote, actually get to the Supreme Court, perhaps with Justice\n",
      "\n",
      "\n",
      "1: It is happening! https://t.co/s7cKZ2gLjQJ\n",
      "\n",
      "\n",
      "2: How can Bill Barr have been in charge of the Justice Department for seven years without making this decision in favor of Mueller & more? But he doesn’t have the lawyers to do such a job!\n",
      "\n",
      "\n",
      "3: The failing @nytimes just reported the Trump campaign is spending $35,000,000,000 on ads. The Times is totally biased & fraudulent!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "ids = torch.tensor(tokenizer.encode(\"<|BOS|>\")).unsqueeze(0)\n",
    "ids = ids.to(device)\n",
    "\n",
    "samples = model.generate(       ids, \n",
    "                                do_sample=True, \n",
    "                                top_k=50, \n",
    "                                max_length = 70, \n",
    "                                num_return_sequences=4\n",
    "                                )\n",
    "\n",
    "for i, sample_output in enumerate(samples):\n",
    "    print(f\"{i}: {tokenizer.decode(sample_output, skip_special_tokens=True)}\\n\\n\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3lYaEivVjaQ"
   },
   "source": [
    "### Top-p sampling\n",
    "Previous method has a drawback - number K of most relevant words is constant, however probability distributions of the next words in fact vary greatly, i.e. after word 'I' or 'The' there is much more equaly likley candidates then after the word 'Airplane'. Top- p sampling calculate cumulative probablity of the most likely words and stops when it hits top_p parameter. Then, number of candidates at each timestamp is not constant anymore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bWGlVERDVjus",
    "outputId": "c1b2dd0d-63fb-4d19-a242-0404ee41ed10"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Despite the many great things the President is doing, the Radical Left Democrats, who are working hard to obstruct and delay, are refusing to go to the Senate because they are afraid of losing the House in the coming Election. They are refusing to show up because our Constitution, the Constitution itself, is not up for them. I have had a long\n",
      "\n",
      "\n",
      "1: We are getting ‘big and fast ‘piggybacking’ in Florida and elsewhere. The New York Times has taken down the Fake News in order to bring it back into relevancy. But what about @DACA? Why isn’t our country moving fast enough? The Dems want to take away everything I\n",
      "\n",
      "\n",
      "2: Watching @CNN @CNN, @washingtonpost, @NBCNews on the big stage, and watching the press conference, like it’s a total double standard. Many things are saying wrong on the show, like the fact that the Lamestream Media and their bosses are not looking very good for the election - just want the\n",
      "\n",
      "\n",
      "3: Crooked Hillary said \"the Fake News is dead.\" What is that? Hillary said we should not have forced our way out - and, ‘I am not going to be forced to do it!’ Wrong!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "ids = torch.tensor(tokenizer.encode(\"<|BOS|>\")).unsqueeze(0)\n",
    "ids = ids.to(device)\n",
    "\n",
    "samples = model.generate(       ids, \n",
    "                                do_sample=True, \n",
    "                                top_k=50, \n",
    "                                max_length = 70,\n",
    "                                top_p=0.92, \n",
    "                                num_return_sequences=4\n",
    "                                )\n",
    "\n",
    "for i, sample_output in enumerate(samples):\n",
    "    print(f\"{i}: {tokenizer.decode(sample_output, skip_special_tokens=True)}\\n\\n\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5omKXliwkqR"
   },
   "source": [
    "We can also specify beginning of the sequence and let model complete it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l9MHlWR9PxFu",
    "outputId": "8aa60fa4-4318-4bb5-b3fa-ad5a40b82927"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Ice cream with my campaign manager, “Nancy Pelosi, for giving up on my campaign. She lost anyway. “I think she is losing to Crooked Hillary” & myself, and she’s not doing very well!” @foxandfriends @foxandfriends @greggwashington \n",
      " https://t\n",
      "\n",
      "\n",
      "1: Ice creamery in Florida is out of control. Fake stories, just as I have reported, are going to be a big source of trouble, and we are going to win big with the people and the “s.”\n",
      "\n",
      "The Fake News Media is totally out of control, and they should be on notice! https://t.\n",
      "\n",
      "\n",
      "2: Ice cream. #FakeNews. Not so great. A terrible day for America today. We are doing a GREAT job, & the Dems don’t have the power!\n",
      "\n",
      "\n",
      "3: Ice cream? I heard ‘I’ve been doing it since I started (and it is amazing).’ What is going on?\n",
      " https://t.co/w7r4q4wKwTm\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "ids  = tokenizer.encode('Ice cream', return_tensors='pt').to(device)\n",
    "ids = ids.to(device)\n",
    "samples = model.generate(       ids, \n",
    "                                do_sample=True, \n",
    "                                top_k=50, \n",
    "                                max_length = 70,\n",
    "                                top_p=0.92, \n",
    "                                num_return_sequences=4\n",
    "                                )\n",
    "\n",
    "for i, sample_output in enumerate(samples):\n",
    "    print(f\"{i}: {tokenizer.decode(sample_output, skip_special_tokens=True)}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbIA419_XjPH"
   },
   "source": [
    "Data:\n",
    "1. https://www.kaggle.com/ayushggarg/all-trumps-twitter-insults-20152021\n",
    "\n",
    "Based on:\n",
    "1. https://huggingface.co/blog/how-to-generate\n",
    "2. https://medium.com/swlh/fine-tuning-gpt-2-for-magic-the-gathering-flavour-text-generation-3bafd0f9bb93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XUw1yG0tYIvT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "trump-tweets.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00d583051f46415eac11b393ec94e0de": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f4e81498061424bb0dde83ac0acee7f",
      "max": 1042301,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c724c430304d4630a0cbe5016d1bb575",
      "value": 1042301
     }
    },
    "0e641c1023ae4f6285237f9e1a6f5546": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "11ec75b0aae54976a3272c4ab16c550b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_21691e53a918498997f4cd456fa6f80f",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_985bb20dd0c644278b521d64c98171af",
      "value": 456318
     }
    },
    "124ce7e129144d1c98138581ee0d2b31": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "173d31bb958e4ad9980666d51defb170": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21691e53a918498997f4cd456fa6f80f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "248c131b02d24c828435831677d63ac0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_173d31bb958e4ad9980666d51defb170",
      "max": 548118077,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_971bacbb7eb44afc857674f725cfa283",
      "value": 548118077
     }
    },
    "26be1de9a7aa422c90a465cb782590a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c084ab5125b4283b4ef7dfe135a3f76",
      "placeholder": "​",
      "style": "IPY_MODEL_daa1b7b794dc4713aefa76f771029e35",
      "value": " 548M/548M [00:10&lt;00:00, 50.4MB/s]"
     }
    },
    "34c3ea38e6c24096984029dbf798028b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_11ec75b0aae54976a3272c4ab16c550b",
       "IPY_MODEL_380a8ea1706f4149a7835a181618b5d0"
      ],
      "layout": "IPY_MODEL_a5ae5ad86ffb483b94ccdf56c801d684"
     }
    },
    "380a8ea1706f4149a7835a181618b5d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c128c8e6580f4159a0d09f44ec242919",
      "placeholder": "​",
      "style": "IPY_MODEL_ffb6cb51d0284310ab7df18074285703",
      "value": " 456k/456k [00:00&lt;00:00, 4.69MB/s]"
     }
    },
    "4c084ab5125b4283b4ef7dfe135a3f76": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f12cad30a194f70b169f588265a6600": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c6c0b2328fe4d96ac8ff4ca47163435",
      "placeholder": "​",
      "style": "IPY_MODEL_0e641c1023ae4f6285237f9e1a6f5546",
      "value": " 665/665 [00:00&lt;00:00, 3.66kB/s]"
     }
    },
    "51fde4bbe58447f7ab6ce3850f63afdb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f4e81498061424bb0dde83ac0acee7f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6566f1451a144451a9bdc90ad29dd0b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af12e10c7fcb4c9a9cad455b8a6e8b05",
      "max": 665,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_67102cf93a364b048c88331980dbd646",
      "value": 665
     }
    },
    "67102cf93a364b048c88331980dbd646": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "7c6c0b2328fe4d96ac8ff4ca47163435": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "885b3c8569b84bf582645a27e9a9534e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "971bacbb7eb44afc857674f725cfa283": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "985bb20dd0c644278b521d64c98171af": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a5ae5ad86ffb483b94ccdf56c801d684": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af12e10c7fcb4c9a9cad455b8a6e8b05": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b7158db477fe4c12878b87e95ad81a83": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_00d583051f46415eac11b393ec94e0de",
       "IPY_MODEL_e1c7b76337a747ef8eca7fef1b9c56f2"
      ],
      "layout": "IPY_MODEL_51fde4bbe58447f7ab6ce3850f63afdb"
     }
    },
    "c128c8e6580f4159a0d09f44ec242919": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c717761fd1d642e68008a9542ad1a38a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_248c131b02d24c828435831677d63ac0",
       "IPY_MODEL_26be1de9a7aa422c90a465cb782590a8"
      ],
      "layout": "IPY_MODEL_d4ff59780f4f4a69926cc1ce122ab45a"
     }
    },
    "c724c430304d4630a0cbe5016d1bb575": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c798caa720de47c496262b19035bc57e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4ff59780f4f4a69926cc1ce122ab45a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "daa1b7b794dc4713aefa76f771029e35": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e1c7b76337a747ef8eca7fef1b9c56f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c798caa720de47c496262b19035bc57e",
      "placeholder": "​",
      "style": "IPY_MODEL_885b3c8569b84bf582645a27e9a9534e",
      "value": " 1.04M/1.04M [00:00&lt;00:00, 5.21MB/s]"
     }
    },
    "eeeff05e1f5c4dde9b0d5b01ae47001a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6566f1451a144451a9bdc90ad29dd0b8",
       "IPY_MODEL_4f12cad30a194f70b169f588265a6600"
      ],
      "layout": "IPY_MODEL_124ce7e129144d1c98138581ee0d2b31"
     }
    },
    "ffb6cb51d0284310ab7df18074285703": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
